{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12816347,"sourceType":"datasetVersion","datasetId":8104360}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mediapipe==0.10.14\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T06:27:49.820703Z","iopub.execute_input":"2026-01-18T06:27:49.821132Z","iopub.status.idle":"2026-01-18T06:27:57.148908Z","shell.execute_reply.started":"2026-01-18T06:27:49.821096Z","shell.execute_reply":"2026-01-18T06:27:57.147457Z"}},"outputs":[{"name":"stdout","text":"Collecting mediapipe==0.10.14\n  Downloading mediapipe-0.10.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (2.3.1)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (25.4.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (25.9.23)\nRequirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (0.7.2)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (0.7.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (3.10.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (2.0.2)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (4.12.0.88)\nCollecting protobuf<5,>=4.25.3 (from mediapipe==0.10.14)\n  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nRequirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (0.5.3)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.14) (2.0.0)\nRequirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.14) (0.5.3)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.14) (3.4.0)\nRequirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.14) (1.15.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (26.0rc2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (2.9.0.post0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.14) (2.23)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.14) (1.17.0)\nDownloading mediapipe-0.10.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, mediapipe\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 5.29.5\n    Uninstalling protobuf-5.29.5:\n      Successfully uninstalled protobuf-5.29.5\n  Attempting uninstall: mediapipe\n    Found existing installation: mediapipe 0.10.31\n    Uninstalling mediapipe-0.10.31:\n      Successfully uninstalled mediapipe-0.10.31\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\na2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.8\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import mediapipe\nimport os\n\nprint(\"1. Location of imported mediapipe:\")\nif hasattr(mediapipe, '__file__'):\n    print(mediapipe.__file__)\nelse:\n    print(\"mediapipe has no __file__ attribute (This is a bad sign).\")\n\nprint(\"\\n2. Files in current directory:\")\nprint(os.listdir())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T06:29:50.496417Z","iopub.execute_input":"2026-01-18T06:29:50.497674Z","iopub.status.idle":"2026-01-18T06:29:50.507353Z","shell.execute_reply.started":"2026-01-18T06:29:50.497620Z","shell.execute_reply":"2026-01-18T06:29:50.505608Z"}},"outputs":[{"name":"stdout","text":"1. Location of imported mediapipe:\n/usr/local/lib/python3.12/dist-packages/mediapipe/__init__.py\n\n2. Files in current directory:\n['.virtual_documents']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import mediapipe as mp\n\n# 1. Manually import the solutions module\nimport mediapipe.python.solutions as solutions\n\n# 2. Assign it back to mp (optional, but keeps your old code working)\nmp.solutions = solutions\n\n# 3. Now try your original setup\nmp_pose = mp.solutions.pose\npose = mp_pose.Pose(min_detection_confidence=0.6, min_tracking_confidence=0.6)\n\nprint(\"Success! Pose module loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T06:30:56.388272Z","iopub.execute_input":"2026-01-18T06:30:56.388660Z","iopub.status.idle":"2026-01-18T06:30:56.497077Z","shell.execute_reply.started":"2026-01-18T06:30:56.388632Z","shell.execute_reply":"2026-01-18T06:30:56.496037Z"}},"outputs":[{"name":"stdout","text":"Success! Pose module loaded.\n","output_type":"stream"},{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1768717856.619470     154 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1768717856.662489     154 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nimport cv2\nimport mediapipe as mp\n\n\nimport math\n\nVIDEO_PATH = '/kaggle/input/newtoetap/Toe Taps.mp4'\nOUTPUT_VIDEO_PATH = 'annotated_toe_taps_final.mp4'\n\nTOUCH_THRESHOLD = 35\nTOUCH_COOLDOWN_FRAMES = 8\nVELOCITY_FRAME_DELTA = 5\n\nLOWER_COLOR_BOUND = np.array([0, 0, 150])\nUPPER_COLOR_BOUND = np.array([180, 60, 255])\n\n# Corrected import for mp_pose\nmp_pose = mp.solutions.pose # Uncommented and using mp.solutions.pose\npose = mp_pose.Pose(min_detection_confidence=0.6, min_tracking_confidence=0.6) # Using mp_pose.Pose\n\ndef find_ball_optimized(frame):\n    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n    mask = cv2.inRange(hsv_frame, LOWER_COLOR_BOUND, UPPER_COLOR_BOUND)\n    mask = cv2.erode(mask, None, iterations=2)\n    mask = cv2.dilate(mask, None, iterations=2)\n    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    best_candidate = None\n    best_score = 0\n    if len(contours) > 0:\n        for c in contours:\n            area = cv2.contourArea(c)\n            if area < 100 or area > 5000:\n                continue\n            perimeter = cv2.arcLength(c, True)\n            if perimeter == 0:\n                continue\n            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n            if 0.7 < circularity < 1.2:\n                if circularity > best_score:\n                    best_score = circularity\n                    best_candidate = c\n    if best_candidate is not None:\n        ((x, y), radius) = cv2.minEnclosingCircle(best_candidate)\n        M = cv2.moments(best_candidate)\n        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n        bbox = (int(x - radius), int(y - radius), int(radius * 2), int(radius * 2))\n        return center, bbox\n    return None, None\n\ndef run_video_analysis(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Error: Could not open video file at '{video_path}'. Please check the path.\")\n        return\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS)) if int(cap.get(cv2.CAP_PROP_FPS)) > 0 else 30\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))\n    print(\"Starting video processing...\")\n    touch_count_left, touch_count_right = 0, 0\n    ball_rotation, player_velocity = \"N/A\", 0.0\n    touch_cooldown = 0\n    player_positions, prev_gray_frame = [], None\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        if prev_gray_frame is None:\n            prev_gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        ball_center, ball_bbox = find_ball_optimized(frame)\n        if ball_center:\n            cv2.rectangle(frame, (ball_bbox[0], ball_bbox[1]),\n                          (ball_bbox[0] + ball_bbox[2], ball_bbox[1] + ball_bbox[3]),\n                          (0, 255, 0), 2)\n        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        results = pose.process(image_rgb)\n        if results.pose_landmarks:\n            landmarks = results.pose_landmarks.landmark\n            left_toe = (int(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].x * width), int(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].y * height)) # Using mp_pose.PoseLandmark\n            right_toe = (int(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].x * width), int(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].y * height)) # Using mp_pose.PoseLandmark\n            left_hip = (int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * width), int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * height)) # Using mp_pose.PoseLandmark\n            right_hip = (int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * width), int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * height)) # Using mp_pose.PoseLandmark\n            player_center = ((left_hip[0] + right_hip[0]) / 2, (left_hip[1] + right_hip[1]) / 2)\n            player_positions.append(player_center)\n            if len(player_positions) > VELOCITY_FRAME_DELTA:\n                player_positions.pop(0)\n            if ball_center and touch_cooldown == 0:\n                dist_left = math.hypot(ball_center[0] - left_toe[0], ball_center[1] - left_toe[1])\n                dist_right = math.hypot(ball_center[0] - right_toe[0], ball_center[1] - right_toe[1])\n                if min(dist_left, dist_right) < TOUCH_THRESHOLD:\n                    touch_cooldown = TOUCH_COOLDOWN_FRAMES\n                    if len(player_positions) == VELOCITY_FRAME_DELTA:\n                        past_pos = player_positions[0]\n                        pixel_dist = math.hypot(player_center[0] - past_pos[0], player_center[1] - past_pos[1])\n                        time_elapsed = VELOCITY_FRAME_DELTA / fps\n                        player_velocity = pixel_dist / time_elapsed if time_elapsed > 0 else 0\n                    if dist_left < dist_right:\n                        touch_count_left += 1\n                    else:\n                        touch_count_right += 1\n        if ball_bbox:\n            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n            ball_roi = gray_frame[ball_bbox[1]:ball_bbox[1]+ball_bbox[3], ball_bbox[0]:ball_bbox[0]+ball_bbox[2]]\n            prev_ball_roi = prev_gray_frame[ball_bbox[1]:ball_bbox[1]+ball_bbox[3], ball_bbox[0]:ball_bbox[0]+ball_bbox[2]]\n            if ball_roi.size > 0 and prev_ball_roi.size > 0 and ball_roi.shape == prev_ball_roi.shape:\n                flow = cv2.calcOpticalFlowFarneback(prev_ball_roi, ball_roi, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n                avg_flow_x = np.mean(flow[..., 0])\n                if avg_flow_x > 1.0: ball_rotation = \"Forward\"\n                elif avg_flow_x < -1.0: ball_rotation = \"Backward\"\n            prev_gray_frame = gray_frame\n        if touch_cooldown > 0:\n            touch_cooldown -= 1\n        cv2.rectangle(frame, (0, height-100), (width, height), (0, 0, 0), -1)\n        cv2.putText(frame, f\"Right Leg Taps: {touch_count_right}\", (20, height - 65), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n        cv2.putText(frame, f\"Left Leg Taps: {touch_count_left}\", (20, height - 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n        cv2.putText(frame, f\"Rotation: {ball_rotation}\", (width - 450, height - 65), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n        cv2.putText(frame, f\"Velocity: {player_velocity:.2f} px/sec\", (width - 450, height - 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n        out.write(frame)\n    cap.release()\n    out.release()\n    print(f\"✅ Processing complete! Annotated video saved to '{OUTPUT_VIDEO_PATH}'\")\nrun_video_analysis(VIDEO_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T06:31:09.962810Z","iopub.execute_input":"2026-01-18T06:31:09.963186Z","iopub.status.idle":"2026-01-18T06:33:14.995310Z","shell.execute_reply.started":"2026-01-18T06:31:09.963157Z","shell.execute_reply":"2026-01-18T06:33:14.994052Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1768717870.126441     159 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1768717870.166012     159 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"name":"stdout","text":"Starting video processing...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n","output_type":"stream"},{"name":"stdout","text":"✅ Processing complete! Annotated video saved to 'annotated_toe_taps_final.mp4'\n","output_type":"stream"}],"execution_count":8}]}